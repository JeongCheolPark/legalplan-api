import logging
from typing import List, Dict, Any
from app.core.config import settings
from app.services.embeddings import get_embeddings_instance
from app.services.llm import get_llm_instance
from app.services.vectorstore import get_vector_stores

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    return "\n\n".join(doc.page_content for doc in docs)

class RagPipeline:
    """ê°„ë‹¨í•œ ê°€ìƒ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„"""
    
    def __init__(self, law_type="all"):
        self.law_type = law_type
        logger.info(f"RagPipeline ì´ˆê¸°í™”: {law_type}")
        
        # ë²¡í„° ìŠ¤í† ì–´, ì„ë² ë”©, LLM ê°€ì ¸ì˜¤ê¸°
        self.vector_stores = get_vector_stores()
        self.embeddings = get_embeddings_instance()
        self.llm = get_llm_instance()
    
    def _get_combined_retriever(self, query):
        """ì—¬ëŸ¬ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì¡°í•©í•œ ë¦¬íŠ¸ë¦¬ë²„ êµ¬í˜„"""
        # law_typeì´ "all"ì´ë©´ ëª¨ë“  ë²¡í„° ìŠ¤í† ì–´ ì‚¬ìš©
        if self.law_type == "all":
            all_docs = []
            
            # ê° ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰
            for name, vector_store in self.vector_stores.items():
                if vector_store is not None:  # None ì²´í¬ ì¶”ê°€
                    retriever = vector_store.as_retriever(
                        search_type="similarity",
                        search_kwargs={"k": 2}  # ê° ë²¡í„° ìŠ¤í† ì–´ì—ì„œ 2ê°œì”© ê°€ì ¸ì˜´
                    )
                    docs = retriever.get_relevant_documents(query)
                    logger.info(f"{name}ì—ì„œ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
                    
                    # ğŸ” ë””ë²„ê¹…: ê²€ìƒ‰ëœ ê° ë¬¸ì„œì˜ ìƒì„¸ ì •ë³´ ì¶œë ¥
                    for i, doc in enumerate(docs):
                        logger.info(f"[{name}] ë¬¸ì„œ {i+1}:")
                        logger.info(f"  - ì¡°ë¬¸: {doc.metadata.get('article', 'N/A')}")
                        logger.info(f"  - ì œëª©: {doc.metadata.get('title', 'N/A')}")
                        logger.info(f"  - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
                    
                    all_docs.extend(docs)
                else:
                    logger.info(f"{name}ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•ŠìŒ (None)")
            
            return all_docs
        else:
            # íŠ¹ì • ë²•ë¥  ë¶„ì•¼ ë²¡í„° ìŠ¤í† ì–´ë§Œ ì‚¬ìš©
            vector_store = self.vector_stores.get(f"{self.law_type}_law")
            if not vector_store:
                logger.warning(f"{self.law_type}_law ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            retriever = vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}
            )
            docs = retriever.get_relevant_documents(query)
            
            # ğŸ” ë””ë²„ê¹…: íŠ¹ì • ë²•ë¥  ê²€ìƒ‰ ê²°ê³¼ë„ ì¶œë ¥
            logger.info(f"{self.law_type}_lawì—ì„œ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
            for i, doc in enumerate(docs):
                logger.info(f"ë¬¸ì„œ {i+1}:")
                logger.info(f"  - ì¡°ë¬¸: {doc.metadata.get('article', 'N/A')}")
                logger.info(f"  - ì œëª©: {doc.metadata.get('title', 'N/A')}")
                logger.info(f"  - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
            
            return docs
        
    def invoke_streaming(self, query):
        """RAG íŒŒì´í”„ë¼ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
        logger.info(f"RAG ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: {query[:30]}...")
        
        # ğŸ” ë””ë²„ê¹…: ê²€ìƒ‰ ì¿¼ë¦¬ ì „ì²´ ì¶œë ¥
        logger.info(f"[ë””ë²„ê¹…] ì „ì²´ ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = self._get_combined_retriever(query)
        logger.info(f"ì´ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
        
        if not docs:
            yield "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return
        
        # 2. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context = format_docs(docs)
        
        # ğŸ” ë””ë²„ê¹…: LLMì— ì „ë‹¬ë  ì»¨í…ìŠ¤íŠ¸ ì¶œë ¥
        logger.info("[ë””ë²„ê¹…] LLMì— ì „ë‹¬ë  ì»¨í…ìŠ¤íŠ¸:")
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)} ë¬¸ì")
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ë‚´ìš©:\n{context[:500]}...\n")  # ì²˜ìŒ 500ìë§Œ ì¶œë ¥
        
        # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_template = """ë‹¹ì‹ ì€ í•œêµ­ ë²•ë¥  ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    ì»¨í…ìŠ¤íŠ¸ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, "ì œê°€ ê°€ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤"ë¼ê³  ì •ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    ì»¨í…ìŠ¤íŠ¸:
    {context}

    ì‚¬ìš©ì ì§ˆë¬¸: {question}

    ë‹µë³€ ì‘ì„± ì§€ì¹¨:
    1. ë²•ë¥  ìš©ì–´ëŠ” ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.
    2. ê´€ë ¨ ë²•ì¡°í•­ì´ ìˆë‹¤ë©´ ëª…ì‹œí•˜ì„¸ìš”.
    3. ë³µì¡í•œ ê°œë…ì€ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
    4. í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” ë‹¨ì •ì ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
    5. ë²•ë¥  ì¡°ì–¸ì´ ì•„ë‹Œ ì •ë³´ ì œê³µ ì°¨ì›ì˜ ë‹µë³€ì„ì„ ëª…ì‹œí•˜ì„¸ìš”.
    """

        prompt = system_template.format(context=context, question=query)
        
        # ğŸ” ë””ë²„ê¹…: ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¶œë ¥
        logger.info(f"[ë””ë²„ê¹…] ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        # 4. ìŠ¤íŠ¸ë¦¬ë° LLM í˜¸ì¶œ
        from app.services.llm import get_streaming_llm
        streaming_llm = get_streaming_llm()
        
        if streaming_llm is None:
            yield "LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return
        
        # 5. ë²„í¼ë¥¼ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (ì—¬ê¸°ê°€ í•µì‹¬ ë³€ê²½ì‚¬í•­!)
        try:
            buffer = ""  # ë²„í¼ ì´ˆê¸°í™”
            
            for chunk in streaming_llm.stream(prompt):
                if hasattr(chunk, 'content') and chunk.content:
                    buffer += chunk.content
                    
                    # think íƒœê·¸ ì²˜ë¦¬ ë° ì „ì†¡
                    processed_content, remaining_buffer = self._process_buffer_with_think_tags(buffer)
                    buffer = remaining_buffer
                    
                    if processed_content:
                        yield processed_content
            
            # ë§ˆì§€ë§‰ ë²„í¼ ë‚´ìš© ì²˜ë¦¬
            if buffer:
                final_content = self._filter_think_tags(buffer)
                if final_content:
                    yield final_content
                    
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            yield f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _process_buffer_with_think_tags(self, buffer):
        """ë²„í¼ì—ì„œ ì™„ì „í•œ think íƒœê·¸ë¥¼ ì°¾ì•„ ì²˜ë¦¬"""
        import re
        
        # think íƒœê·¸ì˜ ì‹œì‘ê³¼ ë ì°¾ê¸°
        think_start = buffer.find('<think>')
        think_end = buffer.find('</think>')
        
        # Case 1: think íƒœê·¸ê°€ ì—†ìŒ
        if think_start == -1:
            # ì „ì²´ ë²„í¼ë¥¼ ì „ì†¡í•˜ê³  ë¹ˆ ë²„í¼ ë°˜í™˜
            return buffer, ""
        
        # Case 2: think íƒœê·¸ê°€ ì‹œì‘í–ˆì§€ë§Œ ëë‚˜ì§€ ì•ŠìŒ
        if think_start != -1 and think_end == -1:
            # think íƒœê·¸ ì´ì „ê¹Œì§€ë§Œ ì „ì†¡
            return buffer[:think_start], buffer[think_start:]
        
        # Case 3: ì™„ì „í•œ think íƒœê·¸ê°€ ìˆìŒ
        if think_start != -1 and think_end != -1 and think_end > think_start:
            # think íƒœê·¸ ì´ì „ ë¶€ë¶„
            before_think = buffer[:think_start]
            # think íƒœê·¸ ì´í›„ ë¶€ë¶„
            after_think = buffer[think_end + 8:]  # 8 = len('</think>')
            
            # ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ì—¬ëŸ¬ think íƒœê·¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
            processed_after, remaining = self._process_buffer_with_think_tags(after_think)
            
            return before_think + processed_after, remaining
        
        # ê·¸ ì™¸ì˜ ê²½ìš° (ë íƒœê·¸ë§Œ ìˆëŠ” ê²½ìš° ë“±)
        return buffer, ""
 
    def _filter_think_tags(self, content):
        """<think> íƒœê·¸ ì œê±°"""
        import re
        # <think>...</think> íƒœê·¸ì™€ ë‚´ìš© ì „ì²´ ì œê±°
        filtered = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
        return filtered.strip()
            
# RAG íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
rag_pipeline = None

def init_rag_pipeline(law_type="all"):
    """RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
    global rag_pipeline
    rag_pipeline = RagPipeline(law_type)
    return rag_pipeline

def get_rag_pipeline():
    """í˜„ì¬ RAG íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ ë˜ëŠ” ì´ˆê¸°í™”"""
    global rag_pipeline
    if rag_pipeline is None:
        return init_rag_pipeline()
    return rag_pipeline